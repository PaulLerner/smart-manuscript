{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# max_len per stroke\n",
    "training set (0+1) | validation set (2) | test set (3)\n",
    "--|--|--\n",
    "289|233|218\n",
    "\n",
    "trim data at 288 because 289 is only divisible by 17 which is a primary number so it's not convenient in regards to pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smart manuscript\n",
    "from smartmanuscript.corpus_iam import _import_set\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style(\"darkgrid\", {'axes.grid' : False})#for prettier plots\n",
    "#math tools\n",
    "import numpy as np\n",
    "#preprocessing\n",
    "from sklearn.preprocessing import scale\n",
    "#machine learning\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"using\",device,\"device\")\n",
    "#io\n",
    "from os.path import join\n",
    "from os.path import exists\n",
    "from os import makedirs\n",
    "from os import listdir\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "#utils\n",
    "from time import time\n",
    "import warnings\n",
    "#custom\n",
    "from parkinson_detection.modules.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_numbers=[0,1,2,3,4]\n",
    "set_number=set_numbers[2]\n",
    "assert set_number in set_numbers\n",
    "iamondo_path=join(\"data\",\"IAMonDo-db-1.0\")\n",
    "max_len=288\n",
    "measure2index={\"x-coordinate\":0,\"y-coordinate\":1}\n",
    "index2measure=list(measure2index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:    \n",
    "    if False:\n",
    "        words, lines = _import_set(iamondo_path, \"{}.set\".format(set_number), max_files=None)\n",
    "\n",
    "        data=np.asarray([stroke for word in words for stroke in  word[1]])\n",
    "    else:\n",
    "        data=np.load(join(\"data\",\"3.set.npy\"))\n",
    "        print(data.shape)\n",
    "    tmp=[]\n",
    "    for stroke in data:\n",
    "        stroke=scale(stroke,axis=0)\n",
    "        if len(stroke) > max_len:\n",
    "            stroke=stroke[:max_len]\n",
    "        else:\n",
    "            stroke=np.concatenate((stroke,np.zeros(shape=(max_len-len(stroke),stroke.shape[1]))))#zero-padding\n",
    "        tmp.append(stroke)\n",
    "    data=np.asarray(tmp)\n",
    "    print(data.shape)\n",
    "    np.save(\"data/padded_3.set.npy\",data)\n",
    "else:\n",
    "    train_set=np.load(join(\"data\",\"padded_0_1.set.npy\"))\n",
    "    test_set=np.load(join(\"data\",\"padded_3.set.npy\"))\n",
    "    train_set=train_set[:,:288]\n",
    "    test_set=test_set[:,:288]\n",
    "    print(train_set.shape)\n",
    "    print(test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Model\n",
    "\n",
    "https://pytorch.org/docs/stable/nn.html#convtranspose1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CNNAutoencoder(torch.nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,conv_kernel,pool_kernel ,padding,\n",
    "                 stride=1,dilation=1, dropout=0.0):\n",
    "        super(CNNAutoencoder, self).__init__()\n",
    "\n",
    "        self.num_layers=len(hidden_size) \n",
    "        \n",
    "        #encoder\n",
    "        self.conv1=torch.nn.utils.weight_norm(\n",
    "            torch.nn.Conv1d(input_size,hidden_size[0],conv_kernel[0],stride=1,padding=padding[0],dilation=dilation[0]))\n",
    "        self.relu1=torch.nn.ReLU()\n",
    "        self.pool1=torch.nn.MaxPool1d(pool_kernel[0],pool_kernel[0],padding=0,dilation=1)\n",
    "        if self.num_layers > 1:\n",
    "            self.drop1=torch.nn.Dropout(dropout)\n",
    "            self.conv2=torch.nn.utils.weight_norm(\n",
    "                torch.nn.Conv1d(hidden_size[0],hidden_size[1],conv_kernel[1],stride=1,padding=padding[1],dilation=dilation[1]))\n",
    "            self.relu2=torch.nn.ReLU()\n",
    "            self.pool2=torch.nn.MaxPool1d(pool_kernel[1],pool_kernel[1],padding=0,dilation=1)\n",
    "        self.drop2=torch.nn.Dropout(dropout)\n",
    "        \n",
    "        #decoder        \n",
    "        if self.num_layers > 1:\n",
    "            self.d_drop2=torch.nn.Dropout(dropout)\n",
    "            self.d_conv2=torch.nn.utils.weight_norm(\n",
    "                torch.nn.ConvTranspose1d(hidden_size[1],hidden_size[0],conv_kernel[1],stride=pool_kernel[1],\n",
    "                                         padding=padding[1],dilation=dilation[1],output_padding=pool_kernel[1]-1))\n",
    "            self.d_relu2=torch.nn.ReLU()\n",
    "        self.d_drop1=torch.nn.Dropout(dropout)\n",
    "        self.d_conv1=torch.nn.utils.weight_norm(\n",
    "            torch.nn.ConvTranspose1d(hidden_size[0],input_size,conv_kernel[0],stride=pool_kernel[0],\n",
    "                                     padding=padding[0],dilation=dilation[0],output_padding=pool_kernel[0]-1))\n",
    "        #self.sigmoid=torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,subject):\n",
    "        c1=self.conv1(subject)\n",
    "        r1=self.relu1(c1)\n",
    "        p1=self.pool1(r1)\n",
    "\n",
    "        if self.num_layers > 1:\n",
    "            drop1=self.drop1(p1)\n",
    "            c2=self.conv2(drop1)\n",
    "            r2=self.relu2(c2)\n",
    "            p2=self.pool2(r2)\n",
    "            drop2=self.drop2(p2)\n",
    "            d_c2=self.d_conv2(drop2)\n",
    "            d_r2=self.d_relu2(d_c2)\n",
    "            d_drop2=self.d_drop2(d_r2)\n",
    "        else:\n",
    "            d_drop2=self.drop2(p1)\n",
    "            \n",
    "        d_c1=self.d_conv1(d_drop2)\n",
    "        \n",
    "        return d_c1#self.sigmoid(d_c1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(input, target, model, optimizer, loss_fn, batch_size,validation = False, device=\"cuda\"):\n",
    "    if not validation:\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    target=target.to(device)\n",
    "    #forward pass\n",
    "    output=model(input)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = loss_fn(output, target)\n",
    "    if not validation:\n",
    "        # Perform backpropagation\n",
    "        loss.backward()\n",
    "        # Adjust model weights\n",
    "        optimizer.step()\n",
    "    return loss.item(), output.squeeze().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout=0.0\n",
    "hidden_size=[16,32]  \n",
    "conv_kernel= [4,4]\n",
    "pool_kernel=[2,2]\n",
    "dilation= [2,2]\n",
    "stride='redef as kernel_size'\n",
    "output_size=\"foo\"\n",
    "\n",
    "padding=[]\n",
    "for d,k in list(zip(dilation,conv_kernel)):\n",
    "    padding.append(d*(k-1)//2)\n",
    "\n",
    "input_size=2\n",
    "batch_size=128\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "\n",
    "learning_rate=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CNNAutoencoder(input_size,hidden_size,conv_kernel,pool_kernel ,padding,stride,dilation, dropout)\n",
    "\n",
    "model=model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject=torch.Tensor(train_set[0].copy()).unsqueeze(0).transpose(1,2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,output=step(subject, subject, model, optimizer, loss_fn, 1)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_measures(task,style=\"-\",index2measure=index2measure):\n",
    "    plt.figure(figsize=(16,12))\n",
    "    for i,measure in enumerate(index2measure):\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.plot(task[:,i],style)\n",
    "        plt.xlabel(\"timesteps\")\n",
    "        plt.ylabel(measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_measures(train_set[0][:50],\".\",index2measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_measures(output.T[:50]\n",
    "              ,\".\",index2measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_task(train_set[0],\".\",measure2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_task(output.T,\".\",measure2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1=model.conv1(subject)\n",
    "r1=model.relu1(c1)\n",
    "p1=model.pool1(r1)\n",
    "\n",
    "if model.num_layers > 1:\n",
    "    drop1=model.drop1(p1)\n",
    "    c2=model.conv2(drop1)\n",
    "    r2=model.relu2(c2)\n",
    "    p2=model.pool2(r2)\n",
    "    drop2=model.drop2(p2)\n",
    "    d_c2=model.d_conv2(drop2)\n",
    "    d_r2=model.d_relu2(d_c2)\n",
    "    d_drop2=model.d_drop2(d_r2)\n",
    "else:\n",
    "    d_drop2=model.drop2(p1)\n",
    "\n",
    "d_c1=model.d_conv1(d_drop2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=3, padding=1),  # b, 16, 10, 10\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2),  # b, 16, 5, 5\n",
    "            nn.Conv2d(16, 8, 3, stride=2, padding=1),  # b, 8, 3, 3\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=1)  # b, 8, 2, 2\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 16, 3, stride=2),  # b, 16, 5, 5\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),  # b, 8, 15, 15\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),  # b, 1, 28, 28\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_c2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_c1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "289/17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_task(train_set[0],measure2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "289/72"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
